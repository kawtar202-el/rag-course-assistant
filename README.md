# RAG Course Assistant

A Retrieval-Augmented Generation (RAG) application to help students ask questions about their course materials using open-source language models from Hugging Face.

## Features

- Process course materials from the `course_materials` folder
- Multiple interface options: command-line, web chat, and Streamlit
- Get answers generated by open-source LLMs
- Clean chat interface with message bubbles

## Prerequisites

- Python 3.8+
- Hugging Face API Token (get one at [https://huggingface.co/settings/tokens](https://huggingface.co/settings/tokens))

## Installation

1. Clone this repository
2. Install requirements:
   ```
   pip install -r requirements.txt
   ```
3. Add your Hugging Face API token to `.env`:
   ```
   HUGGINGFACEHUB_API_TOKEN=your_token_here
   ```

## Usage

### Web Chat Interface 

1. Place your course materials in the `course_materials` folder
2. Start the API server:
   ```
   python -m uvicorn api:app --host 0.0.0.0 --port 8000
   ```
3. Open `chat_interface.html` in your web browser
4. Ask questions about your course materials





## How It Works

1. Documents are loaded and split into chunks
2. Embeddings are created using sentence transformers
3. Vector store is built using FAISS for efficient similarity search
4. When you ask a question, relevant document chunks are retrieved
5. An open-source LLM generates an answer based on the retrieved context

## Technologies Used

- LangChain for orchestration
- Hugging Face models for LLM and embeddings
- FAISS for vector storage
- FastAPI for web backend
- HTML/CSS/JavaScript for web frontend
- Streamlit for the web interface (optional)
- PyPDF2 for PDF processing